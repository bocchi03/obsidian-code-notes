# 《Operating Systems: Three Easy Pieces》

## 第 2 部分：虚拟化 (Virtualization)

### 1. 虚拟化简介

#### 1.1 核心概念

- **虚拟化**: 将物理资源（如 CPU、内存）抽象为虚拟资源，使得多个程序或系统看似独占硬件。
    
- **目标**:
    
    - **有限直接执行 (Limited Direct Execution, LDE)**: 在保证效率的同时控制资源访问。
        
    - 隔离性：进程间互不干扰。
        
    - 资源共享：高效利用硬件。
        

#### 1.2 虚拟化的三大问题

1. **性能**: 如何在虚拟化时尽量减少开销？
    
2. **控制**: 如何限制程序访问未授权资源？
    
3. **透明性**: 如何让程序感觉不到虚拟化的存在？
    

---

## 2. CPU 虚拟化

### 2.1 第 5 章：进程简介

- **进程**: 运行中的程序，是虚拟化 CPU 的基本单位。
    
- **进程状态**:
    
    - 运行 (Running)、就绪 (Ready)、阻塞 (Blocked)。
        
- **数据结构**: 进程控制块 (PCB) 存储进程信息（如寄存器、状态）。
    

### 2.2 第 6 章：有限直接执行

- **基本思想**: 让程序直接在 CPU 上运行，但操作系统通过限制保持控制。
    
- **实现机制**:
    
    - **用户态与内核态**:
        
        - 用户态运行用户程序，内核态运行操作系统。
            
        - 通过系统调用 (System Call) 切换。
            
    - **陷阱 (Trap)**:
        
        - 当程序执行敏感操作（如 I/O 或非法指令）时，陷入内核。
            
    - **定时器中断 (Timer Interrupt)**:
        
        - 操作系统通过定时器抢占 CPU，实现时间分片。
            
- **关键问题**: 如何在程序运行时恢复控制权？
    

### 2.3 第 7 章：CPU 调度

- **调度目标**:
    
    - 最小化周转时间 (Turnaround Time)。
        
    - 最小化响应时间 (Response Time)。
        
- **调度策略**:
    
    - **FIFO (First In, First Out)**: 简单但可能导致“护送效应”。
        
    - **SJF (Shortest Job First)**: 理论上最优，但需要预测运行时间。
        
    - **STCF (Shortest Time-to-Completion First)**: 支持抢占的 SJF。
        
    - **Round Robin**: 公平性好，响应时间优于 FIFO。
        

### 2.4 挑战

- 上下文切换开销：保存和恢复寄存器。
    
- 如何平衡公平性与效率。
    

### 2.5 多级反馈队列

- 新进程默认最高优先级。
    
- 如果进程耗尽时间额度，则降低优先级。
    
- 一段时间，全部进程重新加入最高优先级。
    

---

## 3. 内存虚拟化

### 3.1 第 13 章：地址空间

- **地址空间**: 每个进程拥有独立的虚拟内存空间。
    
- **组成**: 代码、栈、堆。
    
- **目标**:
    
    - 隔离：进程间内存互不干扰。
        
    - 透明性：程序使用虚拟地址，无需关心物理内存。
        

### 3.2 第 14 章：内存虚拟化基础

- **虚拟地址 (VA) 与物理地址 (PA)**:
    
    - 操作系统通过地址转换实现映射。
        
- **硬件支持**:
    
    - **MMU (Memory Management Unit)**: 执行地址翻译。
        
    - **页表 (Page Table)**: 记录 VA 到 PA 的映射。
        

### 3.3 第 15 章：地址翻译机制

- **分页 (Paging)**:
    
    - 将内存分为固定大小的页面（通常 4KB）。
        
    - 虚拟页号 (VPN) 通过页表映射到物理页号 (PFN)。
        
- **页表结构**:
    
    - 包含有效位 (Valid Bit)、权限位 (Permission Bit)、PFN。
        
- **TLB (Translation Lookaside Buffer)**:
    
    - 缓存常用地址映射，减少页表查找开销。
        

### 3.4 第 16 章：分段

- **分段 (Segmentation)**:
    
    - 将地址空间分为逻辑段（如代码段、数据段）。
        
    - 硬件支持：段基址 (Base) 和界限 (Limit)。
        
- **优点**: 灵活性更高。
    
- **缺点**: 碎片问题。
    

### 3.5 第 18 章：分页 - 小型页面

- **页面大小**:
    
    - 小页面（如 4KB）减少内部碎片，但增加页表开销。
        
- **挑战**:
    
    - 页表占用内存较大。
        
    - TLB 未命中率增加。
        

### 3.6 第 20 章：超越物理内存 - 页面置换

- **需求分页 (Demand Paging)**:
    
    - 仅在需要时加载页面到内存。
        
- **页面置换策略**:
    
    - **FIFO**: 简单但可能置换常用页面。
        
    - **LRU (Least Recently Used)**: 更接近最优，但实现复杂。
        
    - **Clock 算法**: LRU 的近似，效率较高。
        
- **换页 (Swapping)**:
    
    - 将不活跃页面写入磁盘的交换区。
        

---

## 4. 虚拟化的关键技术总结

### 4.1 有限直接执行 (LDE)

- CPU 虚拟化的核心：直接运行程序，通过陷阱和中断控制。
    
- 依赖硬件支持（如定时器、特权模式）。
    

### 4.2 地址翻译

- 内存虚拟化的基础：通过分页或分段实现隔离和透明性。
    
- 硬件（MMU、TLB）和软件（页表管理）协作。
    

### 4.3 调度与置换

- 时间分片和页面置换共同解决资源竞争问题。
    

---

## 5. 课后思考

- **CPU 虚拟化**: 如果没有定时器中断，操作系统如何抢占 CPU？
    
- **内存虚拟化**: TLB 未命中如何影响性能？如何优化？
    
- **调度**: 在多核 CPU 上，Round Robin 是否仍是最优选择？
    

## 第 3 部分：并发 (Concurrency)

### 1. 并发简介

#### 1.1 什么是并发？

- **定义**: 多个执行流（如线程或进程）同时运行或交错执行。
    
- **目的**:
    
    - 提高性能：利用多核 CPU。
        
    - 提高响应性：处理多个任务（如 I/O 和计算）。
        
- **挑战**:
    
    - 数据竞争 (Race Condition)。
        
    - 死锁 (Deadlock)。
        
    - 同步开销。
        

#### 1.2 线程 vs 进程

- **线程**: 同一进程内的轻量级执行单元，共享地址空间。
    
- **进程**: 独立的执行单元，拥有独立地址空间。
    
- **书中重点**: 本部分主要讨论线程并发。
    

---

## 2. 线程基础

### 2.1 第 26 章：并发简介

- **线程模型**:
    
    - 一个进程可包含多个线程。
        
    - 每个线程有独立的栈，但共享堆、代码和全局变量。
        
- **创建线程**:
    
    - 示例（伪代码）：
        
         pthread_create(&thread, NULL, worker, NULL);
        
- **问题**:
    
    - 共享内存可能导致非确定性结果。
        

### 2.2 第 27 章：线程 API

- **关键 API**:
    
    - `pthread_create()`: 创建线程。
        
    - `pthread_join()`: 等待线程结束。
        
    - `pthread_exit()`: 线程退出。
        
- **示例**:
    
    - 两个线程同时增加全局计数器，未同步时结果不可预测。
        

---

## 3. 锁 (Locks)

### 3.1 第 28 章：锁 - 基本思想

- **锁的作用**:
    
    - 保护临界区 (Critical Section)，确保一次只有一个线程访问共享资源。
        
- **属性**:
    
    - 互斥 (Mutual Exclusion): 同一时刻仅一个线程持有锁。
        
    - 公平性 (Fairness): 避免线程饥饿。
        
- **简单实现**:
    
    - `lock_t` 和 `unlock_t`（伪代码）：
        
         lock(&mutex);  
         counter++; // 临界区  
         unlock(&mutex);
        

### 3.2 第 29 章：锁 - 实现

- **硬件支持**:
    
    - **测试并设置 (Test-and-Set)**: 原子操作，检查并设置标志。
        
         int TestAndSet(int *ptr, int new) {  
             int old = *ptr;  
             *ptr = new;  
             return old;  
         }
        
    - **比较并交换 (Compare-and-Swap)**: 更灵活的原子操作。
        
- **自旋锁 (Spin Lock)**:
    
     while(TestAndSet(&lock->flag, 1) == 1)  
         ;
    
    - 线程忙等待直到锁可用。
        
    - 适用于短临界区。
        
- **问题**: 自旋锁浪费 CPU 资源。
    

---

## 4. 条件变量 (Condition Variables)

### 4.1 第 30 章：基于锁的并发数据结构

- **示例**:
    
    - **并发计数器**: 用锁保护 `counter++`。
        
    - **并发链表**: 插入/删除操作需锁保护。
        
- **粒度**:
    
    - 粗粒度锁：简单但并发性低。
        
    - 细粒度锁：复杂但并发性高。
        

### 4.2 第 31 章：条件变量

- **定义**: 用于线程间的同步，等待特定条件成立。
    
- **关键 API**:
    
    - `pthread_cond_wait()`: 释放锁并等待。
        
    - `pthread_cond_signal()`: 唤醒一个等待线程。
        
- **经典例子 - 生产者/消费者**:
    
    - 生产者填充缓冲区，消费者取走数据。
        
    - 伪代码：
        
         lock(&mutex);  
         while (buffer_full) {  
             pthread_cond_wait(&cond, &mutex);  
         }  
         add_to_buffer(item);  
         pthread_cond_signal(&cond);  
         unlock(&mutex);
        
- **注意**:
    
    - `while` 而非 `if`，防止伪唤醒 (Spurious Wakeup)。
        

### 4.3 信号量 (Semaphores)

- **定义**:
    
    - 一种计数同步原语，用于控制资源访问或协调线程。
        
    - 由 Dijkstra 提出，包含一个整数值和两个原子操作：`P()`（等待）和 `V()`（释放）。
        
    
     sem_init(&m, 0, x); // 初始化值为x  
     sem_wait(&m); // -1  
     sem_post(&m); // +1
    
- **操作**:
    
    - `P(sem)` (Proberen, 尝试):
        
        - 如果信号量值 > 0，减 1 并继续；否则阻塞。
            
    - `V(sem)` (Verhogen, 增加):
        
        - 信号量值加 1，唤醒一个等待线程。
            
- **实现示例**:
    
    - 用信号量解决生产者-消费者问题：
        
         semaphore empty = N;  // 缓冲区空槽数  
         semaphore full = 0;   // 缓冲区满槽数  
         semaphore mutex = 1;  // 互斥锁  
         ​  
         // 生产者  
         P(&empty);        // 等待空槽  
         P(&mutex);        // 进入临界区  
         add_to_buffer(item);  
         V(&mutex);        // 退出临界区  
         V(&full);         // 增加满槽计数  
         ​  
         // 消费者  
         P(&full);         // 等待满槽  
         P(&mutex);        // 进入临界区  
         remove_from_buffer();  
         V(&mutex);        // 退出临界区  
         V(&empty);        // 增加空槽计数
        
- **用途**:
    
    - **计数信号量**: 限制资源访问（如最多 5 个线程访问数据库）。
        
    - **二元信号量**: 值仅为 0 或 1，类似锁。
        
- **与条件变量对比**:
    
    - 信号量更通用，可直接表示资源数量。
        
    - 条件变量需与锁配合，适合复杂条件等待。
        
- **优点**:
    
    - 简单直观，适合资源计数场景。
        
- **缺点**:
    
    - 误用可能导致死锁或资源泄漏。
        

---

## 5. 并发问题与解决

### 5.1 第 32 章：常见并发问题

- **数据竞争**:
    
    - 两个线程同时访问共享变量，至少一个是写操作。
        
    - 解决：加锁。
        
- **死锁**:
    
    - **条件**:
        
        1. 互斥：资源被独占。
            
        2. 占有并等待：线程持有锁并请求新锁。
            
        3. 不可抢占：锁只能自愿释放。
            
        4. 循环等待：线程间形成环路。
            
    - **预防**:
        
        - 固定加锁顺序。
            
        - 超时重试。
            
- **活锁**: 线程不断尝试但无法进展。
    

---

## 6. 总结

### 6.1 核心概念

- **线程**: 并发执行单元。
    
- **锁**: 保护共享资源。
    
- **条件变量**: 协调线程间依赖。
    

### 6.2 设计原则

- **简单性**: 从粗粒度锁开始。
    
- **正确性**: 优先避免竞争和死锁。
    
- **性能**: 优化锁粒度和等待机制。
    

### 6.3 课后思考

- 自旋锁在多核 CPU 上是否总是高效？
    
- 条件变量如何与锁配合避免忙等待？
    
- 如何检测和调试死锁？
    

## 第 4 部分：持久性 (Persistence)

### 1. 持久性简介

#### 1.1 什么是持久性？

- **定义**: 将数据长期存储在非易失性存储设备（如磁盘、SSD）上，确保系统重启后数据仍然可用。
    
- **目标**:
    
    - 可靠性：数据不丢失。
        
    - 性能：快速读写。
        
    - 容量：支持大规模存储。
        
- **挑战**:
    
    - 硬件限制：磁盘 I/O 比内存慢数个数量级。
        
    - 数据一致性：崩溃时避免数据损坏。
        

#### 1.2 关键设备

- **硬盘 (HDD)**: 机械结构，依赖旋转盘片和磁头。
    
- **固态硬盘 (SSD)**: 基于闪存，无机械部件，速度更快。
    

---

## 2. I/O 与磁盘基础

### 2.1 第 37 章：I/O 设备

- **设备模型**:
    
    - 寄存器接口：数据、命令、状态。
        
    - 操作：轮询 (Polling) 或中断 (Interrupt)。
        
- **操作系统角色**:
    
    - 提供统一接口（如 `read()`、`write()`）。
        
    - 管理设备驱动程序。
        

### 2.2 第 38 章：硬盘

- **结构**:
    
    - 盘片 (Platters)、磁道 (Tracks)、扇区 (Sectors)。
        
    - 寻道时间 (Seek Time)、旋转延迟 (Rotational Delay)、传输时间 (Transfer Time)。
        
- **性能**:
    
    - 顺序访问快，随机访问慢。
        
- **示例**:
    
    - 读取 4KB 数据，典型延迟 ~10ms。
        

---

## 3. 文件系统基础

### 3.1 第 39 章：文件与目录

- **文件**: 字节序列，存储用户数据。
    
- **目录**: 文件的组织结构，包含文件名和元数据。
    
- **API**:
    
    - `open()`, `read()`, `write()`, `close()`。
        
- **抽象**: 文件系统隐藏底层存储细节。
    

### 3.2 第 40 章：文件系统实现

- **数据结构**:
    
    - **索引节点 (inode)**: 存储文件元数据（如大小、位置）。
        
    - **数据块**: 存储文件内容。
        
    - **超级块 (Superblock)**: 文件系统全局信息。
        
- **布局**:
    
    - 磁盘划分为块（通常 4KB）。
        
    - inode 表 + 数据区。
        
- **操作示例**:
    
    - 读取文件：查找 inode -> 获取数据块位置 -> 读取。
        

### 3.3 第 41 章：快速文件系统 (FFS)

- **问题**: 早期文件系统（如 Unix FS）性能差，随机访问多。
    
- **改进**:
    
    - **柱面组 (Cylinder Groups)**: 将相关数据放在附近磁道。
        
    - **大块分配**: 减少碎片，提升顺序访问。
        
- **结果**: 显著提高磁盘利用率和访问速度。
    

---

## 4. 数据一致性与可靠性

### 4.1 第 42 章：文件系统日志 (Journaling)

- **问题**:
    
    - 系统崩溃可能导致元数据或数据不一致。
        
    - 示例：写文件时更新 inode 和数据块，若崩溃发生在两者之间，可能出现指向无效数据的 inode。
        
- **日志机制**:
    
    - 在更新文件系统前记录操作意图到日志（Journal）。
        
    - **步骤**:
        
        1. 写日志：记录即将进行的更改（元数据或数据）。
            
        2. 提交日志：确保日志持久化。
            
        3. 更新磁盘：应用更改到实际文件系统。
            
        4. 清理日志：标记更改完成。
            
- **日志模式**:
    
    - **数据日志 (Data Journaling)**:
        
        - 日志记录元数据和数据。
            
        - 优点：一致性最强。
            
        - 缺点：写放大（数据写两次）。
            
    - **顺序日志 (Ordered Journaling)**:
        
        - 先写数据到磁盘，再写元数据到日志。
            
        - 优点：避免数据重复写，性能更好。
            
        - 缺点：数据可能丢失，但元数据一致。
            
    - **写回日志 (Writeback Journaling)**:
        
        - 元数据写日志，数据直接写磁盘。
            
        - 优点：性能最高。
            
        - 缺点：崩溃可能导致元数据指向旧数据。
            
- **实现**:
    
    - ext3/ext4 支持三种模式，默认 Ordered。
        
- **恢复**:
    
    - 崩溃后重放日志，确保文件系统回到一致状态。
        
- **权衡**:
    
    - 数据日志最安全但慢。
        
    - 写回最快但风险高。
        

### 4.2 第 43 章：日志结构文件系统 (LFS)

- **思想**:
    
    - 将所有写操作视为顺序日志，磁盘只追加数据。
        
    - 避免随机写，提升写性能。
        
- **实现**:
    
    - **数据结构**:
        
        - 日志段 (Segments)：包含数据块、inode 和元数据。
            
        - 检查点 (Checkpoint)：记录文件系统状态。
            
    - **写流程**:
        
        1. 缓冲写操作到内存。
            
        2. 顺序写入日志段。
            
        3. 更新检查点。
            
    - **读流程**:
        
        - 通过 inode 映射表查找最新数据位置。
            
- **清理 (Garbage Collection)**:
    
    - **问题**: 旧数据失效后，日志占用空间增加。
        
    - **解决**:
        
        - 识别活跃块和无效块。
            
        - 压缩日志段，回收空间。
            
    - **代价**: 清理时可能触发额外 I/O。
        
- **优点**:
    
    - 写性能高，适合写密集负载（如数据库）。
        
    - 天然支持崩溃恢复（日志即状态）。
        
- **缺点**:
    
    - 读性能复杂：需要索引查找最新数据。
        
    - 清理开销：可能导致性能抖动。
        
- **应用**:
    
    - 现代 SSD 文件系统（如 F2FS）借鉴 LFS 思想。
        

### 4.3 第 44 章：数据完整性与保护

- **问题**:
    
    - 硬件故障（如磁盘坏块）或传输错误可能导致数据损坏。
        
    - 文件系统需检测和修复错误。
        
- **技术**:
    
    - **校验和 (Checksum)**:
        
        - 为每个数据块计算校验值（如 CRC32）。
            
        - 读时验证数据完整性。
            
        - 示例：ZFS 在每个块存储校验和，检测“静默数据损坏”。
            
    - **冗余 (RAID)**:
        
        - **RAID-0 (条带化)**:
            
            - 数据分片存储到多个磁盘。
                
            - 优点：提升读写性能。
                
            - 缺点：无容错，单盘故障全损。
                
        - **RAID-1 (镜像)**:
            
            - 数据复制到多个磁盘。
                
            - 优点：高可靠性。
                
            - 缺点：容量减半。
                
        - **RAID-4/5 (奇偶校验)**:
            
            - 使用条带化和奇偶校验。
                
            - RAID-4：专用校验盘。
                
            - RAID-5：校验分布到所有盘。
                
            - 恢复：单盘故障时，用奇偶校验重建数据。
                
            - 示例：3 个盘，数据 A、B，校验 P = A XOR B。若盘 1 坏，A = B XOR P。
                
        - **RAID-6**: 双重校验，支持两盘故障。
            
    - **纠删码 (Erasure Coding)**:
        
        - 类似 RAID-5/6，但更灵活。
            
        - 常用于分布式存储（如 Ceph）。
            
- **实现**:
    
    - ZFS 结合校验和与 RAID-Z。
        
    - Btrfs 支持内置 RAID 和校验。
        
- **权衡**:
    
    - 校验和增加计算开销。
        
    - RAID 提高可靠性但成本高。
        

---

## 5. 现代存储技术

### 5.1 SSD 与持久性

- **特点**:
    
    - 无机械部件，随机读写快。
        
    - 磨损均衡 (Wear Leveling) 延长寿命。
        
- **影响**:
    
    - 日志和 LFS 更适合 SSD 的顺序写特性。
        

---

## 6. 总结

### 6.1 核心概念

- **I/O 与磁盘**: 持久性依赖底层存储设备。
    
- **文件系统**: 抽象磁盘，提供文件和目录。
    
- **一致性**: 日志和 LFS 解决崩溃问题。
    
- **可靠性**: 校验和与 RAID 保护数据。
    

### 6.2 设计原则

- **性能**: 优化顺序访问，减少寻道。
    
- **可靠性**: 优先数据一致性。
    
- **简单性**: 从基本文件系统到高级机制逐步改进。
    

### 6.3 课后思考

- 日志的哪种模式最适合高性能数据库？
    
- LFS 的清理如何优化以减少抖动？
    
- RAID-5 和 RAID-6 在多盘故障下的恢复效率差异？
    

## 第 5 部分：分布式系统 (Distributed Systems)

### 1. 分布式系统简介

#### 1.1 什么是分布式系统？

- **定义**: 由多个独立计算机（节点）组成，通过网络通信协同工作，对外表现为一个整体。
    
- **目标**:
    
    - 资源共享：如文件、计算能力。
        
    - 容错性：单点故障不影响整体运行。
        
    - 可扩展性：通过增加节点提升性能。
        
- **挑战**:
    
    - 网络延迟和故障。
        
    - 数据一致性。
        
    - 节点间的同步与协调。
        

---

## 2. 远程过程调用 (RPC)

### 2.1 RPC 简介 (第 48 章)

- **RPC 模型**:
    
    - 允许客户端像调用本地函数一样调用远程服务器上的函数，隐藏网络通信细节。
        
- **工作流程**:
    
    1. 客户端调用 RPC 函数。
        
    2. RPC 库将参数序列化并发送请求。
        
    3. 服务器接收请求，执行函数。
        
    4. 服务器返回结果，客户端反序列化。
        
- **关键问题**:
    
    - **可靠性**: 网络可能丢失消息。
        
    - **性能**: 网络延迟远高于本地调用。
        
    - **接口设计**: 需要明确定义 RPC 服务接口。
        

### 2.2 RPC 实现

- **序列化 (Serialization)**:
    
    - 将参数和返回值转换为字节流，常见格式包括 JSON 和 Protocol Buffers。
        
- **错误处理**:
    
    - 应对网络故障或服务器崩溃，常用策略：重试、设置超时。
        
- **示例**:
    
    - Sun RPC、gRPC。
        

---

## 3. 一致性与共识

### 3.1 一致性模型 (第 49 章)

- **一致性问题**:
    
    - 多副本间数据同步。
        
    - 客户端读写操作的可见性。
        
- **模型**:
    
    - **强一致性 (Strong Consistency)**:
        
        - 所有读操作都能看到最近的写操作结果。
            
        - 实现：同步复制，性能较低。
            
    - **最终一致性 (Eventual Consistency)**:
        
        - 副本最终会收敛到一致状态。
            
        - 实现：异步复制，性能较高。
            
- **权衡**:
    
    - 强一致性牺牲性能，最终一致性牺牲即时性。
        

### 3.2 Paxos 共识算法 (第 50 章)

- **共识问题**:
    
    - 多个节点就某个值达成一致，需容忍部分节点故障。
        
- **Paxos 算法**:
    
    - **角色**: Proposer（提议者）、Acceptor（接受者）、Learner（学习者）。
        
    - **阶段**:
        
        1. **Prepare**: Proposer 提议一个编号。
            
        2. **Accept**: Acceptor 接受最高编号的提议。
            
        3. **Learn**: Learner 学习最终值。
            
- **特点**:
    
    - 容错：少数节点故障不影响结果。
        
    - 复杂：实现和理解难度较高。
        
- **应用**:
    
    - Google Chubby、Apache ZooKeeper。
        

---

## 4. 分布式文件系统

### 4.1 NFS (Network File System) (第 51 章)

- **NFS 模型**:
    
    - 客户端通过网络访问远程文件系统，操作类似本地文件系统。
        
- **实现**:
    
    - **无状态 (Stateless)**: 服务器不维护客户端状态。
        
    - **缓存**: 客户端缓存文件数据以提升性能。
        
- **问题**:
    
    - 一致性：缓存可能导致数据陈旧。
        
    - 性能：受限于网络延迟。
        

### 4.2 GFS (Google File System) (第 52 章)

- **设计目标**:
    
    - 支持大规模数据存储和处理，强调容错和高吞吐量。
        
- **架构**:
    
    - **Master**: 管理元数据。
        
    - **Chunkservers**: 存储数据块 (Chunks)。
        
    - **Clients**: 访问文件。
        
- **特点**:
    
    - **大文件**: 优化大文件的读写操作。
        
    - **副本**: 每个 Chunk 有多个副本以确保容错。
        
    - **一致性**: 宽松一致性，适合 MapReduce 工作负载。
        
- **操作**:
    
    - 读：从最近的 Chunkserver 读取数据。
        
    - 写：通过 Master 协调，写入所有副本。
        

---

## 5. 总结

### 5.1 核心概念

- **RPC**: 简化分布式通信的基础工具。
    
- **一致性**: 在性能和数据同步间寻找平衡。
    
- **共识**: 通过算法确保系统可靠性。
    
- **分布式文件系统**: 提供透明、容错的存储服务。
    

### 5.2 设计原则

- **透明性**: 隐藏网络和故障细节，提升用户体验。
    
- **容错**: 通过冗余和共识算法实现。
    
- **性能**: 优化网络通信和 I/O 操作。
    

### 5.3 课后思考

- RPC 如何应对网络分区问题？
    
- Paxos 在哪些实际场景中是必需的？
    
- GFS 如何处理 Master 单点故障？